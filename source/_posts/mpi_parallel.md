---
title: mpi_parallel
date: 2017/8/11 17:38:58

categories:
- 深度学习
tags:
- deeplearning
- mpi
- caffe
---

 
# 并行程序

## 并行实现实现方式： 
1. 任务并行：将任务分配带若干计算核上; 
2. **数据并行**：将数据进行分割，然后由不同的计算核进行处理，**每个核在规模相当的数据集上大致采用相同的操作**。这不由使我想到了**CAFFE中的对GPU的运用来实现并行训练**的思路，就是将数据集进行分割，每个GPU并行处理各自对应的数据集。 

多指令多数据流又分为分布式内存系统和共享内存系统。 
**分布式内存系统**： 
每个处理器由独立的内存，通过**消息传递函数**来通信。 
共享式内存系统： 
多个处理器能访问内存系统中的相同内存，通过共享内存进行通信。 
**MPI**就是用来在分布式系统中为各处理器进行消息传递的API。 

各个核能够直接访问自己的内存，而运行在不同核之间的进程需要交换内存数据的时候，只能通过消息传递API来实现。消息传递的API至少要提供一个发送函数和接收函数。**进程之间通过它们的序号（rank）**进行识别。


## 并行程序的流程 
a、任务或者**数据划分**，就是要识别出任务中可以进行并行执行的部分。 
b、不同任务之间的**通信**; 
c、**聚合**，将任务和通信进行集合，聚合成更大的任务; 
d、**分配**，将聚合的任务分配到进程或线程中。

# reference

[MPI学习笔记之并行程序概述](http://blog.csdn.net/sinat_22336563/article/details/69486937)