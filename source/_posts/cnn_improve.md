---
title: 神经网络的压缩优化

date: 2017/8/5 12:04:12

categories:
- 深度学习
tags:
- deeplearning
- 网络优化
- 神经网络
---
[TOC]

回顾一下几个经典模型，我们主要看看深度和caffe模型大小，[神经网络模型演化](https://dragonfive.github.io/2017-07-05/deep_learning_model/)

![各种CNN模型][1]

模型大小(参数量)和模型的深浅并非是正相关。

<!--more-->

# 一些经典的模型设计路线

## fully connect to local connect 全连接到卷积神经网络  1x1卷积
Alexnet[1]是一个8层的卷积神经网络，有约**60M个参数**，如果采用**32bit float存下来有200M**。值得一提的是，AlexNet中仍然有3个全连接层，其参数量占比参数总量超过了90%。

下面举一个例子，假如输入为28×28×192，输出feature map通道数为128。那么，直接接3×3卷积，参数量为3×3×192×128=221184。

如果先用**1×1卷积进行降维到96个通道**，然后再用3×3升维到128，则参数量为：1×1×192×96+3×3×96×128=129024，参数量减少一半。虽然参数量减少不是很明显，但是如果1×1输出维度降低到48呢？则参数量又减少一半。对于上千层的大网络来说，效果还是很明显了。

移动端对模型大小很敏感。下载一个100M的app与50M的app，首先用户心理接受程度就不一样。

原则上降低通道数是会降低性能的，这里为什么却可以降维呢？我们可以从很多embedding技术，比如PCA等中得到思考，**降低一定的维度可以去除冗余数据**，损失的精度其实很多情况下都不会对我们解决问题有很大影响。

1×1卷积，在 GoogLeNet Inception v1以及后续版本，ResNet中都大量得到应用，**有减少模型参数**的作用。

## 卷积拆分 

(1) VGG

VGG可以认为是AlexNet的增强版，**两倍的深度，两倍的参数量**。不过，也提出了一个模型压缩的trick，后来也被广泛借鉴。

那就是，**对于5×5的卷积，使用两个3×3的卷积串联**，可以得到同样的感受野，但参数量却有所降低，为3×3×2/(5×5)=0.72，同样的道理3个3×3卷积代替一个7×7，则参数压缩比3×3×3/(7×7)=0.55，降低一倍的参数量，也是很可观的。

(2) GoogLeNet

GoogleLet Inception v2就借鉴了VGG上面的思想。而到了Inception V3网络，则更进一步，将大卷积分解(Factorization)为小卷积。

比如**7×7的卷积，拆分成1×7和7×1**的卷积后。参数量压缩比为1×7×2/(7×7)=0.29，比上面拆分成3个3×3的卷积，更加节省参数了。

问题是这种**非对称的拆分**，居然比对称地拆分成几个小卷积核改进效果更明显，增加了特征多样性。

后来的Resnet就不说了，也是上面这些trick。到现在，基本上网络中都是3×3卷积和1×1卷积，5×5很少见，7×7几乎不可见。




# reference

[知乎:为了压榨CNN模型，这几年大家都干了什么](https://zhuanlan.zhihu.com/p/25797790)


  [1]: https://www.github.com/DragonFive/CVBasicOp/raw/master/1502693251377.jpg